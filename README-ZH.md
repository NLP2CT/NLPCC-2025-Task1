# <p align="center"><font size=50><strong>NLPCC2025 共享任务 1: 大型语言模型生成文本检测</strong></font></p> 

<div style="text-align: center;">
    <a href="https://github.com/NLP2CT/NLPCC-2025-Task1/blob/main/README.md">English HomePage</a>
</div>

# 任务介绍

随着大型语言模型的迅速发展，其生成文本的质量正逐步接近人工撰写的水平。然而，这些模型也带来了诸多挑战，例如可能生成虚假信息、有害内容，或被用于不当用途。因此，如何有效区分大型语言模型生成的文本与人工撰写的文本，已成为一个重要且紧迫的问题。尽管在检测大型语言模型生成文本方面已有显著进展，但相关研究主要集中在英语领域。相比之下，针对中文的研究仍显得相对不足。本次共享任务旨在弥补这一空白，通过开发更强大的检测算法来识别大型语言模型生成的中文文本，从而推动中文领域相关研究的深入发展。

参赛者需要基于提供的原始训练数据，设计并构建检测算法，用以区分大型语言模型生成的文本和人工撰写的文本。在评估阶段，所有提交的检测器将在模拟真实场景的测试条件下（尤其是分布外数据的情况下）进行严格测试，以全面评估其实际效果和鲁棒性。为确保公平性和结果可追溯性，参赛者禁止使用外部数据源或基于外部知识生成新的数据样本。此外，所有训练数据和相关脚本需提交进行审查，以保证任务的公平性、透明性和可复现性。

# 最新消息

- [ 2025.02.27 ] 我们已发布详尽的任务指南和训练数据，快来着手构建属于你自己的高效可靠的检测器吧！

# 数据描述

我们推出了一个名为 DetectRL-ZH 的中文基准测试集，用于检测大语言模型生成的中文文本。该测试集是英文基准测试集 DetectRL 的中文扩展版本。DetectRL-ZH 精心构建了一个模拟现实世界场景中生成文本的数据集，涵盖多样化的内容类型，包括多种释义、对抗性样本以及数据混合样本，从而能够更全面地反映现实中的复杂应用场景。为确保评估结果更具实际意义，我们的测试集设计和评估将同样均基于贴近真实世界的测试场景。以下是本次共享任务所提供数据集的详细统计信息。

## 数据统计

- 训练集：训练集包含来自3种大语言模型和3个领域的数据。具体来说，数据来源包括 ASAP（代表社交媒体评论）、CNewSum（代表新闻写作） 和 CSL（代表学术写作），生成模型包括 GPT-4o、GLM-4-flash 和 Qwen-turbo。训练集总共包含 31,200 个样本。
- 测试集：最终测试使用额外的未知模型和领域数据作为原始数据来源。

| Split | Source    | GPT4o | GLM  | Qwen  | Machine | Human | Total |
|-------|-----------|-------|------|-------|---------|-------|-------|
| Train | ASAP      | 2700  | 2700 | 2700  | 8100    | 2700  | 32400 |
|       | CNewSum   | 2700  | 2700 | 2700  | 8100    | 2700  |       |
|       | CSL       | 2700  | 2700 | 2700  | 8100    | 2700  |       |
| Dev   | -    |   -   | -    | -     | 1700    | 1100  |  2800 |
| Test  | -    | -     | -    | -     | -       | -     | -     |


## 数据下载

训练数据和开发数据可以在以下 Google Drive 或者 Github 文件夹链接中找到：

- Google Drive link: https://drive.google.com/drive/folders/1R5KiW7uwQ002dOE2expEYQLbzQ_gMr8j?usp=sharing

- Github link: https://github.com/NLP2CT/NLPCC2025-Task1/tree/main/data

##  数据限制

- 请注意，所提供的开发集仅限用于模型调优，不允许用于模型训练。

- 为了支持检测系统的开发，允许参赛者基于提供的原始训练数据进行数据增强。然而，数据增强的范围必须严格限定在对原始数据的处理或转换，例如通过裁剪、拆分、词语替换或格式调整等方法生成新的数据样本。所有操作必须确保严格保留原始数据的语义，不得引入任何外部知识或生成完全新创的内容。

- 特别需要强调的是，禁止使用生成式大型语言模型（Generative LLM）进行释义，因为这可能无意间引入分布外知识，从而导致不公平的优势。然而，允许使用传统的编码器模型或序列到序列（seq2seq）模型进行释义操作，前提是严格遵守语义保留的要求。

## 数据格式

数据以 JSON 对象的格式进行存储。

- 训练数据样式:
```json
{
  "text": "text generated by a machine or written by a human",
  "label": "label (human text: 0, machine text: 1)",
  "model": "model that generated the data",
  "source": "source (ASAP, CNewSum, CSL)"
}
```

- 开发集和测试集样式:
```json
{
  "text": "text generated by a machine or written by a human",
  "label": "label (human text: 0, machine text: 1)",
}
```

# 评估指标

该任务的官方评估指标是 F1-Score。这一指标能够综合评估分类器在二元分类任务中的性能，平衡了精确率（Precision）和召回率（Recall），从而提供更加全面的表现测量。

# 提交与评估

测试数据将于 2025 年 4 月 11 日发布。参赛者需根据测试数据生成结果文件并提交（在文件中添加一个“label”字段作为预测结果）。主办方将统一进行系统评估，并于 2025 年 4 月 20 日公布所有参赛者的最终得分和排名。同时，主办方还将发布评估答案，便于参赛者验证自己的结果。比赛结果公布后，参赛者可以着手撰写论文，论文提交的截止日期为 2025 年 5 月 22 日。
提交的预测文件必须是一个包含所有文本的单一 JSON 文件。JSON 文件中的每条记录都需包含“text”和“label”两个字段。

# 重要日期  

| 时间         | 事件                                         |  
| ------------ | -------------------------------------------- |  
| 2025/02/17   | 公布共享任务并发布参赛邀请                   |  
| 2025/02/17   | 开放注册                                     |  
| 2025/02/28   | 发布详细任务指南及训练数据                   |  
| 2025/03/25   | 注册截止                                     |  
| 2025/04/11   | 发布测试数据                                 |  
| 2025/04/20   | 参赛者提交结果的截止日期                     |  
| 2025/04/30   | 公布评估结果并发布系统报告及会议论文邀请     |  
| 2025/05/22   | 会议论文提交截止日期（仅限共享任务）         |  
| 2025/06/12   | 会议论文接收/拒绝通知                        |  
| 2025/06/25   | 终稿论文提交截止日期                         |  

# 奖项

- 任务的前三名参赛队伍将由 NLPCC 和 CCF-NLP 授予证书。

# 主办方 & 联系方式

本次共享任务由澳门大学自然语言处理与中葡机器翻译实验室（NLP2CT Lab）组织。

- [黄辉（Derek, Fai Wong）](https://www.fst.um.edu.mo/personal/derek-wong/)
- [吴俊潮（Junchao Wu）](https://junchaoiu.github.io/)
- [詹润哲（Runzhe Zhan）](https://runzhe.me/) 
- [袁毓林（Yulin Yuan）](https://fah.um.edu.mo/yulin-yuan/)

如果您对本次任务有任何疑问，请发送邮件至 nlp2ct.junchao@gmail.com。

# 常见问题

问: 在哪里可以注册/报名参加本次共享任务？

答: 最新的注册方式可在 NLPCC 2025 共享任务官网（http://tcci.ccf.org.cn/conference/2025/cfpt.php ）上找到。请按照要求填写共享任务 1 的注册表（Word 文档）(http://tcci.ccf.org.cn/conference/2025/sharedTasks/NLPCC2025.SharedTask1.RegistrationForm.doc )，并发送至 nlp2ct.junchao@gmail.com。如有任何疑问，请随时联系。

问: 是否允许使用额外的数据？

答： 不允许使用外部数据源，但允许数据增强（详情请参阅数据限制部分）。

# 参考文献

如果您是该领域的新的研究人员，我们希望以下论文可以帮助您快速熟悉该领域（持续更新中）：

- Wu, J., Yang, S., Zhan, R., Yuan, Y., Chao, L. S., & Wong, D. F. (2025). A survey on LLM-generated text detection: Necessity, methods, and future directions. Computational Linguistics, 1-66.
- Wu, J., Zhan, R., Wong, D. F., Yang, S., Yang, X., Yuan, Y., & Chao, L. S. (2024). DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track.
- Mitchell, E., Lee, Y., Khazatsky, A., Manning, C. D., & Finn, C. (2023, July). Detectgpt: Zero-shot machine-generated text detection using probability curvature. In International Conference on Machine Learning (pp. 24950-24962). PMLR.
- Bao, G., Zhao, Y., Teng, Z., Yang, L., & Zhang, Y. Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature. In The Twelfth International Conference on Learning Representations.
- Hans, A., Schwarzschild, A., Cherepanova, V., Kazemi, H., Saha, A., Goldblum, M., ... & Goldstein, T. (2024, July). Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text. In International Conference on Machine Learning (pp. 17519-17537). PMLR.
- Guo, B., Zhang, X., Wang, Z., Jiang, M., Nie, J., Ding, Y., ... & Wu, Y. (2023). How close is chatgpt to human experts? comparison corpus, evaluation, and detection. arXiv preprint arXiv:2301.07597.
- Wu, J., Zhan, R., Wong, D. F., Yang, S., Liu, X., Chao, L. S., & Zhang, M. (2025, January). Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore. In Proceedings of the 31st International Conference on Computational Linguistics (pp. 10275-10292).
